{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whisper models available here\n",
    "\n",
    "    \"tiny.en\": \"https://openaipublic.azureedge.net/main/whisper/models/d3dd57d32accea0b295c96e26691aa14d8822fac7d9d27d5dc00b4ca2826dd03/tiny.en.pt\",\n",
    "\n",
    "    \"tiny\": \"https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt\",\n",
    "\n",
    "    \"base.en\": \"https://openaipublic.azureedge.net/main/whisper/models/25a8566e1d0c1e2231d1c762132cd20e0f96a85d16145c3a00adf5d1ac670ead/base.en.pt\",\n",
    "\n",
    "    \"base\": \"https://openaipublic.azureedge.net/main/whisper/models/ed3a0b6b1c0edf879ad9b11b1af5a0e6ab5db9205f891f668f8b0e6c6326e34e/base.pt\",\n",
    "\n",
    "    \"small.en\": \"https://openaipublic.azureedge.net/main/whisper/models/f953ad0fd29cacd07d5a9eda5624af0f6bcf2258be67c92b79389873d91e0872/small.en.pt\",\n",
    "\n",
    "    \"small\": \"https://openaipublic.azureedge.net/main/whisper/models/9ecf779972d90ba49c06d968637d720dd632c55bbf19d441fb42bf17a411e794/small.pt\",\n",
    "\n",
    "    \"medium.en\": \"https://openaipublic.azureedge.net/main/whisper/models/d7440d1dc186f76616474e0ff0b3b6b879abc9d1a4926b7adfa41db2d497ab4f/medium.en.pt\",\n",
    "\n",
    "    \"medium\": \"https://openaipublic.azureedge.net/main/whisper/models/345ae4da62f9b3d59415adc60127b97c714f32e89e936602e85993674d08dcb1/medium.pt\",\n",
    "\n",
    "    \"large-v1\": \"https://openaipublic.azureedge.net/main/whisper/models/e4b87e7e0bf463eb8e6956e646f1e277e901512310def2c24bf0e11bd3c28e9a/large-v1.pt\",\n",
    "\n",
    "    \"large-v2\": \"https://openaipublic.azureedge.net/main/whisper/models/81f7c96c852ee8fc832187b0132e569d6c3065a3252ed18e56effd0b6a73e524/large-v2.pt\",\n",
    "\n",
    "    \"large-v3\": \"https://openaipublic.azureedge.net/main/whisper/models/e5b1a55b89c1367dacf97e3e19bfd829a01529dbfdeefa8caeb59b3f1b81dadb/large-v3.pt\",\n",
    "    \n",
    "    \"large\": \"https://openaipublic.azureedge.net/main/whisper/models/e5b1a55b89c1367dacf97e3e19bfd829a01529dbfdeefa8caeb59b3f1b81dadb/large-v3.pt\",\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "\n",
    "model = whisper.load_model(\"model/medium.en.pt\")\n",
    "# model = whisper.load_model(\"large-v3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and time when using GPU acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2-4-3-2-8, good afternoon, what's your sign code? Yes, do you have a transponder code? If not, squawk 0201. Foxtrot's current for the restricted area of the altimeter is 3044, we'll report ghost. Is that guy making a between there? Nope. Oh ye of a little faith, look how big that is. Oh shit! Get it off me! Come on, get it under control, get it out! I've got it, I've got it, I've got it. Get it off me! Get it off me! I-7-4, down and bagel. Get it off the ground. I-7-4, roger, can you give me this?\n"
     ]
    }
   ],
   "source": [
    "# large model gpu inference\n",
    "result = model.transcribe(\"data/apache.mp4\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medium model gpu inference\n",
    "# result = model.transcribe(\"data/apache.mp4\")\n",
    "# print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and time when running cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# medium model cpu inference\n",
    "# result = model.transcribe(\"data/apache.mp4\")\n",
    "# print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df = pd.DataFrame(result['segments'])\n",
    "transcript_df = transcript_df[['start', 'end', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2-4-3-2-8, good afternoon, what's your sign c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yes, do you have a transponder code? If not, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Foxtrot's current for the restricted area of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Is that guy making a between there?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Nope.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start   end                                               text\n",
       "0    0.0   7.0   2-4-3-2-8, good afternoon, what's your sign c...\n",
       "1    7.0  14.0   Yes, do you have a transponder code? If not, ...\n",
       "2   14.0  19.0   Foxtrot's current for the restricted area of ...\n",
       "3   19.0  21.0                Is that guy making a between there?\n",
       "4   21.0  22.0                                              Nope."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email_validator import validate_email, EmailNotValidError\n",
    "email = \"my+address@example.org\"\n",
    "\n",
    "try:\n",
    "\n",
    "  # Check that the email address is valid. Turn on check_deliverability\n",
    "  # for first-time validations like on account creation pages (but not\n",
    "  # login pages).\n",
    "  emailinfo = validate_email(email, check_deliverability=False)\n",
    "\n",
    "  # After this point, use only the normalized form of the email address,\n",
    "  # especially before going to a database query.\n",
    "  email = emailinfo.normalized\n",
    "\n",
    "except EmailNotValidError as e:\n",
    "\n",
    "  # The exception message is human-readable explanation of why it's\n",
    "  # not a valid (or deliverable) email address.\n",
    "  print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my+address'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emailinfo.local_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import get_user\n",
    "test = get_user('blainecperry@gmail.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blainecperry'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original audio is  185.08  seconds\n",
      "Successfully split the audio file into 2 chunks.\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "# Load the large audio file\n",
    "audio = AudioSegment.from_mp3(\"C:/Users/blain/Documents/GitHub/Captains-Log/data/2024-04-02/Untitled.mp3\")\n",
    "\n",
    "print(\"Length of original audio is \",len(audio)/1000, \" seconds\")\n",
    "\n",
    "# Define the chunk length (e.g., 120 seconds)\n",
    "chunk_length = 120 * 1000 # in milliseconds\n",
    "\n",
    "# Break down the audio file into chunks\n",
    "chunks = [audio[i:i + chunk_length] for i in range(0, len(audio), chunk_length)]\n",
    "\n",
    "# Save each chunk as a separate file\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(f\"chunk-{i}.mp3\", format=\"mp3\")\n",
    "\n",
    "print(f\"Successfully split the audio file into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DstTzInfo 'US/Central' LMT-1 day, 18:09:00 STD>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytz\n",
    "pytz.timezone(\"US/Central\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Assuming you have already created a BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(AZURE_CONN_STRING)\n",
    "\n",
    "# Get a reference to the container\n",
    "container_name = \"blainecperry\"\n",
    "container_client = blob_service_client.get_container_client(container_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2024-04-01/log_1.txt', '2024-04-01/log_2.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# List \"logs\" within a date subfolder\n",
    "subfolder_prefix = \"2024-04-01/\"\n",
    "all_logs = container_client.list_blobs(name_starts_with=subfolder_prefix)\n",
    "\n",
    "log_list = [log.name for log in all_logs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "for log in log_list:\n",
    "    # Get a reference to the blob\n",
    "    blob_client = container_client.get_blob_client(log)\n",
    "    \n",
    "    # Download the blob content\n",
    "    blob_data = blob_client.download_blob()\n",
    "\n",
    "    # Read the content of the blob as text\n",
    "    content = blob_data.readall()\n",
    "\n",
    "    entries.append(content.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs_in_folder = container_client.list_blobs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the folder prefix\n",
    "folder_prefix = \"\"\n",
    "\n",
    "# Extract unique subfolder names\n",
    "subfolders = set()\n",
    "\n",
    "for blob in blobs_in_folder:\n",
    "    # Get the blob name relative to the folder prefix\n",
    "    relative_blob_name = blob.name[len(folder_prefix):]\n",
    "\n",
    "    # Extract the subfolder name (if any)\n",
    "    subfolder = relative_blob_name.split(\"/\", 1)[0]\n",
    "    \n",
    "    # Add the subfolder to the set\n",
    "    subfolders.add(subfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2024-03-31', '2024-04-01', '2024-04-02', '2024-04-03'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subfolders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
